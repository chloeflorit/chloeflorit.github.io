---
  layout: post
title: HW 3
---
  
  In this blog post, I’ll discuss image classification with tensor flow. 

# §1. Obtaining Data

## Working with Datasets

```python
plt.figure(figsize=(10, 10))
listDogs = []
listCats = []
for images, labels in train_dataset.take(1):
  for i in range(25):
    u = [labels[i]][0]
    if u.numpy()==1:
      listDogs.append(i)
    else:
      listCats.append(i)
  listCats1 = listCats [:3]
  listDogs1 = listDogs [:3]

  
  k = 0
  for j in listCats1:
    k = k+1
    ax = plt.subplot(2, 3, k)
    plt.imshow(images[j].numpy().astype("uint8"))
    plt.title("cat")
    plt.axis("off")

  k=3
  for l in listDogs1:
    k=k+1
    ax = plt.subplot(2, 3, k)
    plt.imshow(images[l].numpy().astype("uint8"))
    plt.title("dog")
    plt.axis("off")
```
 ![image-example.png](/images/catsAndDogs.png)

## Check Label Frequencies
We will compute the number of images in the training data with label 0 (corresponding to "cat") and label 1 (corresponding to "dog").

``` python 
cats = 0
dogs = 0

for images,labels in train_dataset.take(1):
  for i in range (32):
    myTensor = [labels[i]][0] #determines label of image
    valueMyTensor = myTensor.numpy() #converts label value to a numpy
    
    if valueMyTensor == 0:
      cats = cats + 1 #if the value is 0, then the image is a cat
  
  dogs = 32-cats

print(cats)
print(dogs)
```
Then the most frequent label is dogs (20).
The accuracy of the baseline model is 20/32 (62.5%). 
 
 # §2. First model
The parse full credits method will go to each of the actors' webpages on IMDB. 
Then it will call the parse_actor method which will look at the filmography for each actor. 
 ```python
model1 = tf.keras.Sequential([
  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(32, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(64, (3, 3), activation='relu'),
  layers.Flatten(),
  layers.Dense(64, activation='relu'),
  layers.Dropout(.2)

])
 ```
  ```python
model1.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])

history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
   ```
 ![image-example.png](/images/model1History.png)
 The accuracy of my model stabilized between **61% and 63%** during training. 
 My model performed the same as a baseline model. 
 We do observe overfitting in model 1, where the training accuracy is between **85% and 90%**.

# §3. Model with Data Augmentation
First, create a `tf.keras.layers.RandomFlip()` layer. Make a plot of the original image and a few copies to which RandomFlip() has been applied. Make sure to check the documentation for this function!
```python

for image, _ in train_dataset.take(1):
  first_image = image[0]

plt.figure(figsize=(10, 10))

for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  augmented_image = randomFlip(tf.expand_dims(first_image, 0))
  plt.imshow(augmented_image[0] / 255)
  plt.axis('off')
```
![image-example.png](/images/rotation.png)

Next, create a `tf.keras.layers.RandomRotation()` layer. Check the docs to learn more about the arguments accepted by this layer. Then, make a plot of both the original image and a few copies to which RandomRotation() has been applied.

```python
from keras.layers.preprocessing.image_preprocessing import RandomRotation
randomRotation = tf.keras.layers.RandomRotation(0.2)

plt.figure(figsize=(10, 10))

for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  augmented_image = randomRotation(tf.expand_dims(first_image, 0))
  plt.imshow(augmented_image[0] / 255)
  plt.axis('off')
```
![image-example.png](/images/rotationOff.png)

Now, create a new `tf.keras.models.Sequential` model called model2 in which the first two layers are augmentation layers.

```python
model2= tf.keras.Sequential([
  layers.RandomFlip("horizontal_and_vertical"),
  layers.RandomRotation(0.2),                            
  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(32, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(64, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(64, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Flatten(),
  layers.Dense(64, activation='relu'),
  layers.Dropout(.2)

])

model2.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])

history2 = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
])
```
**The validation accuracy is between 55% and 60%**
The model performs worse than model1.
Overfitting does not occur in our model where the traininng accuracy is between 50% and 55%. 

![image-example.png](/images/model2History.png)

# §4. Data Preprocessing

```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])

model3= tf.keras.Sequential([
  preprocessor,
  layers.RandomFlip("horizontal_and_vertical"),
  layers.RandomRotation(0.2),                            
  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(32, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(64, (3, 3), activation='relu'),
  layers.Flatten(),
  layers.Dense(64, activation='relu'),
  layers.Dropout(.2)
])

model3.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])

history3 = model3.fit(train_dataset, 
                     epochs=5, 
                     validation_data=validation_dataset)
```

# §5. Transfer Learning
```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

```python
model4= tf.keras.Sequential([
  preprocessor,
  base_model_layer,
  layers.RandomFlip("horizontal_and_vertical"),
  layers.RandomRotation(0.2),  
  layers.Flatten(),                          
  layers.Dense(64, activation='relu'),
])

model4.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])

history4 = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
![image-example.png](/images/model4History.png)
**The validation of my model during training is between 97% and 99%**
The validation accuracy is much better than model1, which has a validation accuracy between 61% and 63%.
There is no overfitting since the training accuracy is about 99%. 

Summary of model4:

```python
model4.summary()
```
![image-example.png](/images/summary.png)

# §6. Score on Test Data

Let's evaluate the accuracy of your most performant model on the unseen `test_dataset`
```python
loss, accuracy = model4.evaluate(test_dataset)
print('Test accuracy :', accuracy)
```
![image-example.png](/images/testAccuracy.png)



