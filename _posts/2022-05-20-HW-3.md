---
  layout: post
title: HW 3
---
  
  In this blog post, I’ll discuss image classification with tensor flow. 

# §1. Obtaining Data

## Working with Datasets
We will write a function to create a two-row visualization, where 3 cats are in the first row and 3 dogs are in the second row. 
```python

def rowCatsDogs(a):
    """
    function puts three random pictures of cats on the first row and 
    three random pictures of dogs on the second row
    """
    plt.figure(figsize=(10, 10)) 
    listDogs = [] #will contain the label indices of the dog images 
    listCats = [] #will contain the label indices of the cat images 
    for images, labels in train_dataset.take(1):
        for i in range(25):
            u = [labels[i]][0] #finds the value of the label
            if u.numpy()==1: #if the value is 1 then it is a dog
                listDogs.append(i) 
            else: i #if the value is 0 then it is a cat
                listCats.append(i)
  
    listCats1 = listCats [:3] #we choose only the first 3 elements of the list
    listDogs1 = listDogs [:3] 

  
    k = 0
    for j in listCats1:
        k = k+1
        ax = plt.subplot(2, 3, k) #plots images on the first line
        plt.imshow(images[j].numpy().astype("uint8")) #show the image
        plt.title("cat")
        plt.axis("off")

    k=3
    for l in listDogs1:
        k=k+1
        ax = plt.subplot(2, 3, k)
        plt.imshow(images[l].numpy().astype("uint8"))
        plt.title("dog")
        plt.axis("off")
```
 ![image-example.png](/images/catsAndDogs.png)

## Check Label Frequencies
We will compute the number of images in the training data with label 0 (corresponding to "cat") and label 1 (corresponding to "dog").

``` python 
cats = 0
dogs = 0

for images,labels in train_dataset.take(1):
  for i in range (32):
    myTensor = [labels[i]][0] #determines label of image
    valueMyTensor = myTensor.numpy() #converts label value to a numpy
    
    if valueMyTensor == 0:
      cats = cats + 1 #if the value is 0, then the image is a cat
  
  dogs = 32-cats

print(cats)
print(dogs)
```
Then the most frequent label is dogs (20).
The accuracy of the baseline model is 20/32 (62.5%). 
 
 # §2. First model
Let's create our first model. 
 ```python
model1 = tf.keras.Sequential([
  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(32, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(64, (3, 3), activation='relu'),
  layers.Flatten(),
  layers.Dense(64, activation='relu'),
  layers.Dropout(.2)

])
 ```
 Next, we will compile and train our model.
  ```python
  
model1.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])

history = model1.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
   ```
 ![image-example.png](/images/model1History.png)
 The accuracy of my model stabilized between **61% and 63%** during training. 
 My model performed the same as a baseline model. 
 We do observe overfitting in model 1, where the training accuracy is between **85% and 90%**.

# §3. Model with Data Augmentation
First, we will create a `tf.keras.layers.RandomFlip()` layer. Next, we will make a plot of the original image and a few copies to which RandomFlip() has been applied. 
```python

for image, _ in train_dataset.take(1):
  first_image = image[0] #picks an random image from the first image

plt.figure(figsize=(10, 10))

for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  augmented_image = randomFlip(tf.expand_dims(first_image, 0)) #applies randomFlip to the image
  plt.imshow(augmented_image[0] / 255)
  plt.axis('off')
```
![image-example.png](/images/rotation.png)

Next, we will create a `tf.keras.layers.RandomRotation()` layer. Then, we will make a plot of both the original image and a few copies to which RandomRotation() has been applied.

```python
from keras.layers.preprocessing.image_preprocessing import RandomRotation
randomRotation = tf.keras.layers.RandomRotation(0.2)

plt.figure(figsize=(10, 10))

for i in range(9):
  ax = plt.subplot(3, 3, i + 1)
  augmented_image = randomRotation(tf.expand_dims(first_image, 0)) #randomly rotates the image
  plt.imshow(augmented_image[0] / 255) 
  plt.axis('off')
```
![image-example.png](/images/rotationOff.png)

Now, let's create a new `tf.keras.models.Sequential` model called model2 in which the first two layers are augmentation layers.

```python
model2= tf.keras.Sequential([
  layers.RandomFlip("horizontal_and_vertical"),
  layers.RandomRotation(0.2),                            
  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(32, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(64, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(64, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Flatten(),
  layers.Dense(64, activation='relu'),
  layers.Dropout(.2)

])

model2.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])

history2 = model2.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
])
```
**The validation accuracy is between 55% and 60%**
The model performs worse than model1.
Overfitting does not occur in our model where the traininng accuracy is between 50% and 55%. 

![image-example.png](/images/model2History.png)

# §4. Data Preprocessing

The following code will create a preprocessing layer called preprocessor.
We will incorporate the preprocessor layer as the very first layer, before the data augmentation layers. 

```python
i = tf.keras.Input(shape=(160, 160, 3))
x = tf.keras.applications.mobilenet_v2.preprocess_input(i)
preprocessor = tf.keras.Model(inputs = [i], outputs = [x])

model3= tf.keras.Sequential([
  preprocessor,
  layers.RandomFlip("horizontal_and_vertical"),
  layers.RandomRotation(0.2),                            
  layers.Conv2D(32, (3, 3), activation='relu', input_shape=(160, 160, 3)),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(32, (3, 3), activation='relu'),
  layers.MaxPooling2D((2, 2)),
  layers.Conv2D(64, (3, 3), activation='relu'),
  layers.Flatten(),
  layers.Dense(64, activation='relu'),
  layers.Dropout(.2)
])

model3.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])

history3 = model3.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```

**The validation accuracy is between 70% and 72%**
The model performs better than model1.
Overfitting does not occur in our model where the traininng accuracy is between 65% and 70%. 


# §5. Transfer Learning

we could use a pre-existing model for our image recognition task.
To do this, we need to first access a pre-existing “base model”, incorporate it into a full model for our current task, and then train that model.

```python
IMG_SHAPE = IMG_SIZE + (3,)
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')
base_model.trainable = False

i = tf.keras.Input(shape=IMG_SHAPE)
x = base_model(i, training = False)
base_model_layer = tf.keras.Model(inputs = [i], outputs = [x])
```

```python
model4= tf.keras.Sequential([
  preprocessor,
  base_model_layer,
  layers.RandomFlip("horizontal_and_vertical"),
  layers.RandomRotation(0.2),  
  layers.Flatten(),                          
  layers.Dense(64, activation='relu'),
])

model4.compile(optimizer='adam', 
              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics = ['accuracy'])

history4 = model4.fit(train_dataset, 
                     epochs=20, 
                     validation_data=validation_dataset)
```
![image-example.png](/images/model4History.png)
**The validation of my model during training is between 97% and 99%**
The validation accuracy is much better than model1, which has a validation accuracy between 61% and 63%.
There is no overfitting since the training accuracy is about 99%. 

Summary of model4:

```python
model4.summary()
```
![image-example.png](/images/summary.png)

# §6. Score on Test Data

Let's evaluate the accuracy of your most performant model on the unseen `test_dataset`
```python
loss, accuracy = model4.evaluate(test_dataset)
print('Test accuracy :', accuracy)
```
![image-example.png](/images/testAccuracy.png)

The accuracy is 98%. My model performed very well. 



